class LinkedInScraper:

    url_l = "https://www.linkedin.com/jobs/search/?keywords=college+internship"

    soup_l = bs4.BeautifulSoup(requests.get(url_l).text, "html.parser")

    def l_listings(soup_l):
        infos = []
        listings_container = soup_l.find("ul", class_="jobs-search__results-list")
        if listings_container:
            listings = listings_container.find_all("li")
            for info in listings:
                job = info.find('h3')
                company = info.find('h4')
                location = info.find('span', class_='job-search-card__location')
                url = info.find('a', class_='base-card__full-link')['href']
                posted = info.find('time')['datetime']
                if posted:
                    posted_date = datetime.datetime.strptime(posted, "%Y-%m-%d")
                    now = datetime.datetime.now()
                    recent_post = now - datetime.timedelta(days=14)
                    if posted_date >= recent_post:
                        infos.append({
                            'job': job.text.strip() if job else None,
                            'company': company.text.strip() if company else None,
                            'location': location.text.strip() if location else None,
                            'url': url if url else None,
                            'posted': posted if posted else None
                        })
        return infos

class GoogleScraper:            
    @staticmethod
    def search_api(user_query, total_results, params, url, ignore_keywords, results_per_page):
        queries = [
            f'{user_query} internships',
            f'{user_query} companies',
            f'{user_query} internship requirements',
            f'{user_query} ideal internship and career path'
        ]
        all_results = []
        for query in queries:
            current_start = 1
            results_fetched = 0
            while results_fetched < total_results:
                params['q'] = query
                response = requests.get(url, params=params)
                results = response.json()
                if 'items' in results:
                    for item in results['items']:
                        title = item.get('title', 'No title available')
                        link = item.get('link', 'No link available')
                        snippet = item.get('snippet', 'No snippet available')
                        if any(keyword in title.lower() for keyword in ignore_keywords) or \
                           any(keyword in link.lower() for keyword in ignore_keywords) or \
                           any(keyword in snippet.lower() for keyword in ignore_keywords):
                            continue
                        # Optionally check for 200 status code
                        try:
                            head_resp = requests.head(link, timeout=3, allow_redirects=True)
                            if head_resp.status_code == 200:
                                all_results.append({
                                    'title': title,
                                    'link': link,
                                    'snippet': snippet,
                                    'category': query.replace(user_query, '').strip()
                                })
                                results_fetched += 1
                        except Exception:
                            continue
                        if results_fetched >= total_results:
                            break
                else:
                    break
                current_start += results_per_page
        return all_results

    if __name__ == '__main__':
        user_input = input('Degree: ')          # User input should be recieved from app or website not console
        queries = [
            f'{user_input} internships',
            f'{user_input} companies',
            f'{user_input} internship requirements',
            f'{user_input} ideal internship and career path'
        ]


        url = 'https://customsearch.googleapis.com/customsearch/v1'
        ignore_keywords = ['linkedin', 'indeed', 'wikipedia']
        current_start = 1
        results_fetched = 0
        total_results = 40      # Total results fetched
        results_per_page = 10 

        params = {
            'key': 'AIzaSyDRev_yjHadZmkCkxqYP8Y4XzxEahLp1gA',
            'cx': '23c933d7a0f4840b0',
            'q': queries,
            'start': 40
        }
        search_api(queries, total_results, params, url, ignore_keywords, results_per_page)
